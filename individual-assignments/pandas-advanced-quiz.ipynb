{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "504bc240-69ca-43e6-b1f3-7b262d56cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue by Region:\n",
      "    Region   Revenue\n",
      "0     East       0.0\n",
      "1    North  180000.0\n",
      "2    South  100000.0\n",
      "3  Unknown   45000.0\n",
      "4     West  180000.0\n",
      "\n",
      "Region with highest revenue: North ($180000.0)\n"
     ]
    }
   ],
   "source": [
    "#Pandas Library – Part 2\n",
    "#Question 1\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sales_data.csv')\n",
    "\n",
    "df['Revenue'] = df['Units Sold'] * df['Unit Price']\n",
    "\n",
    "# Grouping by region and calculate total revenue\n",
    "revenue_by_region = df.groupby('Region')['Revenue'].sum().reset_index()\n",
    "\n",
    "highest_revenue_region = revenue_by_region.loc[revenue_by_region['Revenue'].idxmax()]\n",
    "\n",
    "print(\"Revenue by Region:\")\n",
    "print(revenue_by_region)\n",
    "print(f\"\\nRegion with highest revenue: {highest_revenue_region['Region']} (${highest_revenue_region['Revenue']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cf158ea-7bd2-4e5f-aaff-e12d789712a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Salary by Department:\n",
      "  Department   Salary\n",
      "0    Finance  81000.0\n",
      "1         HR  35000.0\n",
      "2         IT  78000.0\n",
      "\n",
      "Average Years of Experience by Department:\n",
      "  Department  Years of Experience\n",
      "0    Finance                 10.0\n",
      "1         HR                  3.0\n",
      "2         IT                  6.5\n",
      "\n",
      "Department with most experienced employees: Finance (10.0 years average)\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('employee_data.csv')\n",
    "\n",
    "avg_salary_by_dept = df.groupby('Department')['Salary'].mean().reset_index()\n",
    "\n",
    "# Calculating average years of experience by department\n",
    "avg_exp_by_dept = df.groupby('Department')['Years of Experience'].mean().reset_index()\n",
    "\n",
    "most_exp_dept = avg_exp_by_dept.loc[avg_exp_by_dept['Years of Experience'].idxmax()]\n",
    "\n",
    "print(\"Average Salary by Department:\")\n",
    "print(avg_salary_by_dept)\n",
    "print(\"\\nAverage Years of Experience by Department:\")\n",
    "print(avg_exp_by_dept)\n",
    "print(f\"\\nDepartment with most experienced employees: {most_exp_dept['Department']} ({most_exp_dept['Years of Experience']:.1f} years average)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b66188be-a500-4fee-b896-8abf652a7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature-to-Humidity Ratio by City:\n",
      "          City  Temp-to-Humidity Ratio\n",
      "0     New York                1.214286\n",
      "1  Los Angeles                1.800000\n",
      "3      Houston                1.672727\n",
      "4      Phoenix                2.600000\n",
      "\n",
      "City with Highest Temperature-to-Humidity Ratio:\n",
      "City                      Phoenix\n",
      "Temperature (°F)            104.0\n",
      "Humidity (%)                 40.0\n",
      "Rainfall (inches)             0.0\n",
      "Temp-to-Humidity Ratio        2.6\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Question 3\n",
    "import pandas as pd\n",
    "\n",
    "weather_data = pd.read_csv(\"weather_data.csv\")\n",
    "\n",
    "weather_data = weather_data.dropna(subset=[\"Temperature (°F)\", \"Humidity (%)\", \"City\"])\n",
    "weather_data = weather_data[weather_data[\"Humidity (%)\"] > 0]\n",
    "weather_data[\"Temp-to-Humidity Ratio\"] = weather_data[\"Temperature (°F)\"] / weather_data[\"Humidity (%)\"]\n",
    "\n",
    "highest_ratio_city = weather_data.loc[weather_data[\"Temp-to-Humidity Ratio\"].idxmax()]\n",
    "\n",
    "print(\"Temperature-to-Humidity Ratio by City:\")\n",
    "print(weather_data[[\"City\", \"Temp-to-Humidity Ratio\"]])\n",
    "print(\"\\nCity with Highest Temperature-to-Humidity Ratio:\")\n",
    "print(highest_ratio_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa9d1801-edb3-465b-86ed-5a6a16c42216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Order Amount by City with Customer ID:\n",
      "          City  Customer ID  Amount\n",
      "0      Houston          4.0   500.0\n",
      "1  Los Angeles          2.0   450.0\n",
      "2        Miami          5.0   600.0\n",
      "3     New York          1.0   300.0\n"
     ]
    }
   ],
   "source": [
    "#Question 4\n",
    "import pandas as pd\n",
    "\n",
    "customers_file_path = \"customers.csv\"\n",
    "orders_file_path = \"orders.csv\"\n",
    "\n",
    "customers_data = pd.read_csv(customers_file_path)\n",
    "orders_data = pd.read_csv(orders_file_path)\n",
    "\n",
    "customers_data = customers_data.dropna(subset=[\"Customer ID\", \"City\"])\n",
    "orders_data = orders_data.dropna(subset=[\"Customer ID\", \"Amount\"])\n",
    "\n",
    "merged_data = pd.merge(customers_data, orders_data, on=\"Customer ID\", how=\"inner\")\n",
    "\n",
    "average_order_amount_per_city = merged_data.groupby([\"City\", \"Customer ID\"])[\"Amount\"].mean().reset_index()\n",
    "\n",
    "print(\"Average Order Amount by City with Customer ID:\")\n",
    "print(average_order_amount_per_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5eb59eef-edd1-4fcb-9896-d9f940f2ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year-over-Year Growth Analysis:\n",
      "   Year Region    Sales  YoY Growth (%)\n",
      "3  2023  South  47000.0        4.444444\n",
      "\n",
      "Most Consistent Growth Region:\n",
      "No valid regions with consistent growth data.\n"
     ]
    }
   ],
   "source": [
    "#Question 5\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"multi_year_sales.csv\"\n",
    "\n",
    "multi_year_sales_data = pd.read_csv(file_path)\n",
    "\n",
    "multi_year_sales_data = multi_year_sales_data.dropna(subset=[\"Year\", \"Region\", \"Sales\"])\n",
    "\n",
    "multi_year_sales_data[\"Year\"] = multi_year_sales_data[\"Year\"].astype(int)\n",
    "\n",
    "multi_year_sales_data = multi_year_sales_data.sort_values(by=[\"Region\", \"Year\"])\n",
    "multi_year_sales_data[\"YoY Growth (%)\"] = multi_year_sales_data.groupby(\"Region\")[\"Sales\"].pct_change() * 100\n",
    "multi_year_sales_data = multi_year_sales_data.dropna(subset=[\"YoY Growth (%)\"])\n",
    "\n",
    "if multi_year_sales_data.empty:\n",
    "    most_consistent_region = \"No valid data available for YoY Growth analysis.\"\n",
    "else:\n",
    "    growth_variability = multi_year_sales_data.groupby(\"Region\")[\"YoY Growth (%)\"].std().reset_index()\n",
    "    growth_variability = growth_variability.dropna()\n",
    "    if growth_variability.empty:\n",
    "        most_consistent_region = \"No valid regions with consistent growth data.\"\n",
    "    else:\n",
    "        most_consistent_region = growth_variability.loc[growth_variability[\"YoY Growth (%)\"].idxmin()]\n",
    "\n",
    "print(\"Year-over-Year Growth Analysis:\")\n",
    "print(multi_year_sales_data)\n",
    "print(\"\\nMost Consistent Growth Region:\")\n",
    "print(most_consistent_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5b67322-b017-4c37-ac38-baf4abfa1cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Products by Units Sold:\n",
      "   Product  Units Sold\n",
      "0  Monitor       300.0\n",
      "1  Scanner       250.0\n",
      "2   Tablet       200.0\n",
      "3  Desktop       180.0\n",
      "4   Laptop       150.0\n",
      "5  Printer         0.0\n",
      "\n",
      "Top-Selling Product:\n",
      "Product           Desktop\n",
      "Total Revenue    180000.0\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Contribution to Total Revenue (%):\n",
      "31.03448275862069\n"
     ]
    }
   ],
   "source": [
    "#Question 6\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"sales_data.csv\"\n",
    "\n",
    "sales_data = pd.read_csv(file_path)\n",
    "\n",
    "sales_data = sales_data.dropna(subset=[\"Product\", \"Units Sold\", \"Unit Price\"])\n",
    "sales_data[\"Total Revenue\"] = sales_data[\"Units Sold\"] * sales_data[\"Unit Price\"]\n",
    "\n",
    "top_selling_product = sales_data.groupby(\"Product\")[\"Total Revenue\"].sum().reset_index()\n",
    "top_selling_product = top_selling_product.sort_values(by=\"Total Revenue\", ascending=False).iloc[0]\n",
    "\n",
    "total_revenue = sales_data[\"Total Revenue\"].sum()\n",
    "\n",
    "top_product_contribution = (top_selling_product[\"Total Revenue\"] / total_revenue) * 100\n",
    "\n",
    "ranked_products = sales_data.groupby(\"Product\")[\"Units Sold\"].sum().reset_index()\n",
    "ranked_products = ranked_products.sort_values(by=\"Units Sold\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Ranked Products by Units Sold:\")\n",
    "print(ranked_products)\n",
    "print(\"\\nTop-Selling Product:\")\n",
    "print(top_selling_product)\n",
    "print(\"\\nContribution to Total Revenue (%):\")\n",
    "print(top_product_contribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a7abfc6-110f-4125-b8df-6ce4c2198563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough valid data available for correlation analysis.\n"
     ]
    }
   ],
   "source": [
    "#Question 7\n",
    "import pandas as pd\n",
    "employee_data_path = \"employee_data.csv\"\n",
    "weather_data_path = \"weather_data.csv\"\n",
    "\n",
    "employee_data = pd.read_csv(employee_data_path)\n",
    "weather_data = pd.read_csv(weather_data_path)\n",
    "employee_data = employee_data.dropna(subset=[\"Salary\", \"Department\"])\n",
    "weather_data = weather_data.dropna(subset=[\"City\", \"Temperature (°F)\", \"Humidity (%)\"])\n",
    "merged_data = pd.merge(employee_data, weather_data, left_on=\"Department\", right_on=\"City\", how=\"inner\")\n",
    "average_salary_per_city = merged_data.groupby(\"City\")[\"Salary\"].mean().reset_index()\n",
    "\n",
    "salary_weather_correlation = pd.merge(average_salary_per_city, weather_data, on=\"City\", how=\"inner\")\n",
    "\n",
    "if not salary_weather_correlation.empty:\n",
    "    correlation_matrix = salary_weather_correlation[[\"Salary\", \"Temperature (°F)\", \"Humidity (%)\"]].corr()\n",
    "    print(\"Correlation between Salary and Weather Conditions:\")\n",
    "    print(correlation_matrix)\n",
    "else:\n",
    "    print(\"Not enough valid data available for correlation analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "edbaae17-c537-4ae9-a397-91d6f597b442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Missing Values in Each Column:\n",
      "Product        0.000000\n",
      "Units Sold    28.571429\n",
      "Unit Price     0.000000\n",
      "Region        28.571429\n",
      "dtype: float64\n",
      "\n",
      "Updated Sales Data with Missing Values Handled:\n",
      "      Product  Units Sold  Unit Price Region\n",
      "0      Laptop       150.0        1200  North\n",
      "1      Tablet       200.0         500  South\n",
      "2  Smartphone         NaN         800   East\n",
      "3     Desktop       180.0        1000   West\n",
      "4     Monitor       300.0         150   <NA>\n",
      "5     Printer         NaN         200   East\n",
      "6     Scanner       250.0         300    NaN\n"
     ]
    }
   ],
   "source": [
    "#Pandas Library- Part 3\n",
    "#Question 1\n",
    "import pandas as pd\n",
    "file_path = \"sales_data.csv\"\n",
    "sales_data = pd.read_csv(file_path)\n",
    "sales_data.loc[sales_data[\"Units Sold\"] == 0, \"Units Sold\"] = pd.NA\n",
    "sales_data.loc[sales_data[\"Region\"] == \"Unknown\", \"Region\"] = pd.NA\n",
    "missing_values_percentage = sales_data.isna().mean() * 100\n",
    "print(\"Percentage of Missing Values in Each Column:\")\n",
    "print(missing_values_percentage)\n",
    "print(\"\\nUpdated Sales Data with Missing Values Handled:\")\n",
    "print(sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "94999709-8e8c-43fa-80e5-9872200e7fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Sales Data with Filled Missing Units Sold:\n",
      "      Product  Units Sold  Unit Price Region\n",
      "0      Laptop       150.0        1200  North\n",
      "1      Tablet       200.0         500  South\n",
      "2  Smartphone         NaN         800   East\n",
      "3     Desktop       180.0        1000   West\n",
      "4     Monitor         NaN         150   <NA>\n",
      "5     Printer         NaN         200   East\n",
      "6     Scanner         NaN         300    NaN\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "import pandas as pd\n",
    "file_path = \"sales_data.csv\"\n",
    "\n",
    "sales_data = pd.read_csv(file_path)\n",
    "sales_data.loc[sales_data[\"Units Sold\"] == 0, \"Units Sold\"] = pd.NA\n",
    "sales_data.loc[sales_data[\"Region\"] == \"Unknown\", \"Region\"] = pd.NA\n",
    "sales_data[\"Units Sold\"] = sales_data.groupby(\"Region\")[\"Units Sold\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "print(\"\\nUpdated Sales Data with Filled Missing Units Sold:\")\n",
    "print(sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "48d31e67-9fbc-421d-b0f9-12c4e2aea6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Data with Forward Fill (Salary):\n",
      "   Employee ID     Name Department   Salary  Years of Experience\n",
      "0          101    Alice         HR  70000.0                  3.0\n",
      "1          102      Bob    Finance  80000.0                  NaN\n",
      "2          103  Charlie         IT  80000.0                  6.0\n",
      "3          104    Diana    Finance  82000.0                 10.0\n",
      "4          105    Ethan         IT  78000.0                  7.0\n",
      "5          106    Fiona        NaN  65000.0                  4.0\n",
      "6          107      NaN         HR      0.0                  NaN\n",
      "\n",
      "Employee Data with Backward Fill (Years of Experience):\n",
      "   Employee ID     Name Department   Salary  Years of Experience\n",
      "0          101    Alice         HR  70000.0                  3.0\n",
      "1          102      Bob    Finance  80000.0                  6.0\n",
      "2          103  Charlie         IT      NaN                  6.0\n",
      "3          104    Diana    Finance  82000.0                 10.0\n",
      "4          105    Ethan         IT  78000.0                  7.0\n",
      "5          106    Fiona        NaN  65000.0                  4.0\n",
      "6          107      NaN         HR      0.0                  NaN\n"
     ]
    }
   ],
   "source": [
    "#Question 3\n",
    "import pandas as pd\n",
    "file_path = \"employee_data.csv\"\n",
    "employee_data = pd.read_csv(file_path)\n",
    "\n",
    "employee_data_ffill = employee_data.copy()\n",
    "employee_data_ffill[\"Salary\"] = employee_data_ffill[\"Salary\"].ffill()\n",
    "\n",
    "employee_data_bfill = employee_data.copy()\n",
    "employee_data_bfill[\"Years of Experience\"] = employee_data_bfill[\"Years of Experience\"].bfill()\n",
    "\n",
    "print(\"Employee Data with Forward Fill (Salary):\")\n",
    "print(employee_data_ffill)\n",
    "print(\"\\nEmployee Data with Backward Fill (Years of Experience):\")\n",
    "print(employee_data_bfill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5bd58ffb-2a0a-4a63-9db2-f62e8266457c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Data with Department Mean Salary Imputation:\n",
      "   Employee ID     Name Department   Salary  Years of Experience\n",
      "0          101    Alice         HR  70000.0                  3.0\n",
      "1          102      Bob    Finance  80000.0                  NaN\n",
      "2          103  Charlie         IT  78000.0                  6.0\n",
      "3          104    Diana    Finance  82000.0                 10.0\n",
      "4          105    Ethan         IT  78000.0                  7.0\n",
      "5          106    Fiona        NaN      NaN                  4.0\n",
      "6          107      NaN         HR      0.0                  NaN\n"
     ]
    }
   ],
   "source": [
    "#Question 4\n",
    "import pandas as pd\n",
    "file_path = \"employee_data.csv\"\n",
    "employee_data = pd.read_csv(file_path)\n",
    "\n",
    "employee_data[\"Salary\"] = employee_data.groupby(\"Department\")[\"Salary\"].transform(lambda x: x.fillna(x.mean()))\n",
    "print(\"Employee Data with Department Mean Salary Imputation:\")\n",
    "print(employee_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e73e5993-ee32-4547-849a-d34c4c05e4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data with Linear Interpolation:\n",
      "          City  Temperature (°F)  Humidity (%)  Rainfall (inches)\n",
      "0     New York              85.0          70.0                1.2\n",
      "1  Los Angeles              90.0          50.0                0.5\n",
      "2      Chicago              91.0          60.0                2.3\n",
      "3      Houston              92.0          55.0                NaN\n",
      "4      Phoenix             104.0          40.0                0.0\n",
      "5      Seattle              60.0           0.0                0.8\n",
      "6        Miami              88.0           NaN                NaN\n",
      "\n",
      "Weather Data with Polynomial Interpolation (Degree 2):\n",
      "          City  Temperature (°F)  Humidity (%)  Rainfall (inches)\n",
      "0     New York         85.000000          70.0                1.2\n",
      "1  Los Angeles         90.000000          50.0                0.5\n",
      "2      Chicago         87.412037          60.0                2.3\n",
      "3      Houston         92.000000          55.0                NaN\n",
      "4      Phoenix        104.000000          40.0                0.0\n",
      "5      Seattle         60.000000           0.0                0.8\n",
      "6        Miami         88.000000           NaN                NaN\n"
     ]
    }
   ],
   "source": [
    "#Question 5\n",
    "import pandas as pd\n",
    "file_path = \"weather_data.csv\"\n",
    "weather_data = pd.read_csv(file_path)\n",
    "\n",
    "weather_data_linear = weather_data.copy()\n",
    "weather_data_linear[\"Temperature (°F)\"] = weather_data_linear[\"Temperature (°F)\"].interpolate(method='linear')\n",
    "weather_data_poly = weather_data.copy()\n",
    "weather_data_poly[\"Temperature (°F)\"] = weather_data_poly[\"Temperature (°F)\"].interpolate(method='polynomial', order=2)\n",
    "\n",
    "print(\"Weather Data with Linear Interpolation:\")\n",
    "print(weather_data_linear)\n",
    "print(\"\\nWeather Data with Polynomial Interpolation (Degree 2):\")\n",
    "print(weather_data_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82a7a954-1527-4624-84f6-8ca3fb452d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data After Dropping Rainfall Column:\n",
      "          City  Temperature (°F)  Humidity (%)  Rainfall (inches)\n",
      "0     New York              85.0          70.0                1.2\n",
      "1  Los Angeles              90.0          50.0                0.5\n",
      "2      Chicago               NaN          60.0                2.3\n",
      "3      Houston              92.0          55.0                NaN\n",
      "4      Phoenix             104.0          40.0                0.0\n",
      "5      Seattle              60.0           0.0                0.8\n",
      "6        Miami              88.0           NaN                NaN\n"
     ]
    }
   ],
   "source": [
    "#Question 6\n",
    "import pandas as pd\n",
    "file_path = \"weather_data.csv\"\n",
    "weather_data = pd.read_csv(file_path)\n",
    "missing_percentage = weather_data.isna().mean() * 100\n",
    "if missing_percentage[\"Rainfall (inches)\"] > 50:\n",
    "   weather_data_dropped = weather_data.drop(columns=[\"Rainfall (inches)\"])\n",
    "else:\n",
    "   weather_data_dropped = weather_data.copy()\n",
    "\n",
    "print(\"Weather Data After Dropping Rainfall Column:\")\n",
    "print(weather_data_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ef8ce85f-1997-4c77-ba1c-495040a827f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Year Sales Data After Multi-Column Imputation:\n",
      "     Year Region    Sales\n",
      "0  2022.0  North  50000.0\n",
      "1  2022.0  South  45000.0\n",
      "2  2023.0  North  46000.0\n",
      "3  2023.0  South  47000.0\n",
      "4  2023.0   East  48000.0\n",
      "5  2024.0    NaN      0.0\n",
      "6  2025.0   West  60000.0\n"
     ]
    }
   ],
   "source": [
    "#Question 7\n",
    "import pandas as pd\n",
    "file_path = \"multi_year_sales.csv\"\n",
    "multi_year_sales_data = pd.read_csv(file_path)\n",
    "\n",
    "multi_year_sales_data[\"Sales\"] = multi_year_sales_data[\"Sales\"].interpolate(method='linear')\n",
    "\n",
    "if multi_year_sales_data[\"Year\"].isna().sum() > 0:\n",
    "   existing_years = multi_year_sales_data[\"Year\"].dropna().unique()\n",
    "   existing_years.sort()\n",
    "   min_year, max_year = int(existing_years.min()), int(existing_years.max())\n",
    "   full_year_range = list(range(min_year, max_year + 1))\n",
    "   multi_year_sales_data[\"Year\"] = multi_year_sales_data[\"Year\"].ffill().bfill()\n",
    "\n",
    "print(\"Multi-Year Sales Data After Multi-Column Imputation:\")\n",
    "print(multi_year_sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dd41c692-41ba-4004-9741-f17378d46a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales Data with Revenue Column:\n",
      "   Product  Units Sold  Unit Price   Region  Total Revenue\n",
      "0   Laptop       150.0        1200    North       180000.0\n",
      "1   Tablet       200.0         500    South       100000.0\n",
      "3  Desktop       180.0        1000     West       180000.0\n",
      "4  Monitor       300.0         150  Unknown        45000.0\n",
      "5  Printer         0.0         200     East            0.0\n",
      "\n",
      "Total Revenue by Region:\n",
      "    Region  Total Revenue\n",
      "0     East            0.0\n",
      "1    North       180000.0\n",
      "2    South       100000.0\n",
      "3  Unknown        45000.0\n",
      "4     West       180000.0\n",
      "\n",
      "Difference between Highest and Lowest Revenue:\n",
      "180000.0\n"
     ]
    }
   ],
   "source": [
    "#Pandas Library- Part 4\n",
    "#Question 1\n",
    "import pandas as pd\n",
    "file_path = \"sales_data.csv\"\n",
    "sales_data = pd.read_csv(file_path)\n",
    "sales_data = sales_data.dropna(subset=[\"Units Sold\", \"Unit Price\", \"Region\"])\n",
    "sales_data[\"Total Revenue\"] = sales_data[\"Units Sold\"] * sales_data[\"Unit Price\"]\n",
    "region_revenue = sales_data.groupby(\"Region\")[\"Total Revenue\"].sum().reset_index()\n",
    "revenue_difference = region_revenue[\"Total Revenue\"].max() - region_revenue[\"Total Revenue\"].min()\n",
    "print(\"Sales Data with Revenue Column:\")\n",
    "print(sales_data)\n",
    "print(\"\\nTotal Revenue by Region:\")\n",
    "print(region_revenue)\n",
    "print(\"\\nDifference between Highest and Lowest Revenue:\")\n",
    "print(revenue_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04574f7d-67fa-492c-94d8-895d50ecea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Data with Salary Difference:\n",
      "   Employee ID   Name Department   Salary  Years of Experience  \\\n",
      "0          101  Alice         HR  70000.0                  3.0   \n",
      "3          104  Diana    Finance  82000.0                 10.0   \n",
      "4          105  Ethan         IT  78000.0                  7.0   \n",
      "1          102    Bob    Finance  80000.0                  NaN   \n",
      "6          107    NaN         HR      0.0                  NaN   \n",
      "\n",
      "   Salary Difference  \n",
      "0            35000.0  \n",
      "3             1000.0  \n",
      "4                0.0  \n",
      "1            -1000.0  \n",
      "6           -35000.0  \n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "import pandas as pd\n",
    "file_path = \"employee_data.csv\"\n",
    "employee_data = pd.read_csv(file_path)\n",
    "employee_data = employee_data.dropna(subset=[\"Salary\", \"Department\"])\n",
    "department_avg_salary = employee_data.groupby(\"Department\")[\"Salary\"].transform(\"mean\")\n",
    "employee_data[\"Salary Difference\"] = employee_data[\"Salary\"] - department_avg_salary\n",
    "employee_data_sorted = employee_data.sort_values(by=\"Salary Difference\", ascending=False)\n",
    "print(\"Employee Data with Salary Difference:\")\n",
    "print(employee_data_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1635f5ae-d1ff-4d98-9463-603008e63e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Data with Experience Level:\n",
      "   Employee ID     Name Department   Salary  Years of Experience  \\\n",
      "0          101    Alice         HR  70000.0                  3.0   \n",
      "2          103  Charlie         IT      NaN                  6.0   \n",
      "3          104    Diana    Finance  82000.0                 10.0   \n",
      "4          105    Ethan         IT  78000.0                  7.0   \n",
      "5          106    Fiona        NaN  65000.0                  4.0   \n",
      "\n",
      "  Experience Level  \n",
      "0           Junior  \n",
      "2        Mid-level  \n",
      "3        Mid-level  \n",
      "4        Mid-level  \n",
      "5           Junior  \n"
     ]
    }
   ],
   "source": [
    "#Question 3\n",
    "import pandas as pd\n",
    "file_path = \"employee_data.csv\"\n",
    "employee_data = pd.read_csv(file_path)\n",
    "employee_data = employee_data.dropna(subset=[\"Years of Experience\"])\n",
    "\n",
    "def categorize_experience(years):\n",
    "    if years < 5:\n",
    "        return \"Junior\"\n",
    "    elif 5 <= years <= 10:\n",
    "        return \"Mid-level\"\n",
    "    else:\n",
    "        return \"Senior\"\n",
    "\n",
    "employee_data[\"Experience Level\"] = employee_data[\"Years of Experience\"].apply(categorize_experience)\n",
    "print(\"Employee Data with Experience Level:\")\n",
    "print(employee_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "22ff6dc6-c63f-4db0-bcd8-0d7cd6ed79a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data with Humidity-to-Temperature Ratio:\n",
      "          City  Temperature (°F)  Humidity (%)  Rainfall (inches)  \\\n",
      "0     New York              85.0          70.0                1.2   \n",
      "1  Los Angeles              90.0          50.0                0.5   \n",
      "3      Houston              92.0          55.0                NaN   \n",
      "4      Phoenix             104.0          40.0                0.0   \n",
      "5      Seattle              60.0           0.0                0.8   \n",
      "\n",
      "   Humidity-to-Temperature Ratio  \n",
      "0                       0.823529  \n",
      "1                       0.555556  \n",
      "3                       0.597826  \n",
      "4                       0.384615  \n",
      "5                       0.000000  \n",
      "\n",
      "City with the Highest Humidity-to-Temperature Ratio:\n",
      "City                             New York\n",
      "Temperature (°F)                     85.0\n",
      "Humidity (%)                         70.0\n",
      "Rainfall (inches)                     1.2\n",
      "Humidity-to-Temperature Ratio    0.823529\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Question 4\n",
    "import pandas as pd\n",
    "file_path = \"weather_data.csv\"\n",
    "weather_data = pd.read_csv(file_path)\n",
    "weather_data = weather_data.dropna(subset=[\"Temperature (°F)\", \"Humidity (%)\", \"City\"])\n",
    "weather_data[\"Humidity-to-Temperature Ratio\"] = weather_data[\"Humidity (%)\"] / weather_data[\"Temperature (°F)\"]\n",
    "highest_ratio_city = weather_data.loc[weather_data[\"Humidity-to-Temperature Ratio\"].idxmax()]\n",
    "print(\"Weather Data with Humidity-to-Temperature Ratio:\")\n",
    "print(weather_data)\n",
    "print(\"\\nCity with the Highest Humidity-to-Temperature Ratio:\")\n",
    "print(highest_ratio_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "66258ef2-06de-4ac0-ba2c-1f2eff37544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data with Rainfall Categories:\n",
      "          City  Temperature (°F)  Humidity (%)  Rainfall (inches)  \\\n",
      "0     New York              85.0          70.0                1.2   \n",
      "1  Los Angeles              90.0          50.0                0.5   \n",
      "4      Phoenix             104.0          40.0                0.0   \n",
      "5      Seattle              60.0           0.0                0.8   \n",
      "\n",
      "  Rainfall Category  \n",
      "0         High Rain  \n",
      "1          Low Rain  \n",
      "4           No Rain  \n",
      "5          Low Rain  \n",
      "\n",
      "Average Temperature by Rainfall Category:\n",
      "  Rainfall Category  Temperature (°F)\n",
      "0         High Rain              85.0\n",
      "1          Low Rain              75.0\n",
      "2           No Rain             104.0\n"
     ]
    }
   ],
   "source": [
    "#Question 5\n",
    "import pandas as pd\n",
    "file_path = \"weather_data.csv\"\n",
    "weather_data = pd.read_csv(file_path)\n",
    "weather_data = weather_data.dropna(subset=[\"Rainfall (inches)\", \"Temperature (°F)\"])\n",
    "\n",
    "def categorize_rainfall(rainfall):\n",
    "    if rainfall == 0:\n",
    "        return \"No Rain\"\n",
    "    elif 0 < rainfall <= 1:\n",
    "        return \"Low Rain\"\n",
    "    else:\n",
    "        return \"High Rain\"\n",
    "\n",
    "weather_data[\"Rainfall Category\"] = weather_data[\"Rainfall (inches)\"].apply(categorize_rainfall)\n",
    "avg_temp_by_rainfall = weather_data.groupby(\"Rainfall Category\")[\"Temperature (°F)\"].mean().reset_index()\n",
    "print(\"Weather Data with Rainfall Categories:\")\n",
    "print(weather_data)\n",
    "print(\"\\nAverage Temperature by Rainfall Category:\")\n",
    "print(avg_temp_by_rainfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f1bd68e0-bd35-48c8-a36d-06418a11d17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Year Sales Data with YoY Growth:\n",
      "   Year Region    Sales  YoY Growth (%)\n",
      "3  2023  South  47000.0        4.444444\n",
      "\n",
      "Most Consistent Growth Region:\n",
      "No valid regions with consistent growth data.\n"
     ]
    }
   ],
   "source": [
    "#Question 6\n",
    "import pandas as pd\n",
    "file_path = \"multi_year_sales.csv\"\n",
    "multi_year_sales_data = pd.read_csv(file_path)\n",
    "multi_year_sales_data = multi_year_sales_data.dropna(subset=[\"Year\", \"Region\", \"Sales\"])\n",
    "multi_year_sales_data[\"Year\"] = multi_year_sales_data[\"Year\"].astype(int)\n",
    "multi_year_sales_data = multi_year_sales_data.sort_values(by=[\"Region\", \"Year\"])\n",
    "multi_year_sales_data[\"YoY Growth (%)\"] = multi_year_sales_data.groupby(\"Region\")[\"Sales\"].pct_change() * 100\n",
    "multi_year_sales_data = multi_year_sales_data.dropna(subset=[\"YoY Growth (%)\"])\n",
    "\n",
    "if not multi_year_sales_data.empty:\n",
    "    growth_variability = multi_year_sales_data.groupby(\"Region\")[\"YoY Growth (%)\"].std().reset_index()\n",
    "    growth_variability = growth_variability.dropna()\n",
    "    if not growth_variability.empty:\n",
    "        most_consistent_region = growth_variability.loc[growth_variability[\"YoY Growth (%)\"].idxmin()]\n",
    "    else:\n",
    "        most_consistent_region = \"No valid regions with consistent growth data.\"\n",
    "else:\n",
    "    most_consistent_region = \"No valid data available for YoY Growth analysis.\"\n",
    "\n",
    "print(\"Multi-Year Sales Data with YoY Growth:\")\n",
    "print(multi_year_sales_data)\n",
    "print(\"\\nMost Consistent Growth Region:\")\n",
    "print(most_consistent_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c07cc69b-27b7-4b17-a703-473cb9112c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Sales Analysis by Region:\n",
      "  Region  Total_Sales  Average_Yearly_Sales  Years_Above_50K\n",
      "0  North      50000.0               50000.0                0\n",
      "1  South      92000.0               46000.0                0\n",
      "2   West      60000.0               60000.0                1\n"
     ]
    }
   ],
   "source": [
    "#Question 7\n",
    "import pandas as pd\n",
    "file_path = \"multi_year_sales.csv\"\n",
    "multi_year_sales_data = pd.read_csv(file_path)\n",
    "multi_year_sales_data = multi_year_sales_data.dropna(subset=[\"Year\", \"Region\", \"Sales\"])\n",
    "multi_year_sales_data[\"Year\"] = multi_year_sales_data[\"Year\"].astype(int)\n",
    "\n",
    "aggregated_sales = multi_year_sales_data.groupby(\"Region\").agg(\n",
    "    Total_Sales=(\"Sales\", \"sum\"),\n",
    "    Average_Yearly_Sales=(\"Sales\", \"mean\"),\n",
    "    Years_Above_50K=(\"Sales\", lambda x: (x > 50000).sum())\n",
    ").reset_index()\n",
    "\n",
    "print(\"Aggregated Sales Analysis by Region:\")\n",
    "print(aggregated_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e869a1d-4ca2-40c3-8ec6-3a16a0d0dcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
